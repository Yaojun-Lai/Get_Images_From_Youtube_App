{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjJWO_nz8K82",
        "outputId": "c9a68fb1-0843-4dcc-e22b-15a3f86e2c95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gGhlbhI8TrW",
        "outputId": "032c518d-7a70-41a0-fb13-c28f180a7ed5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "sYmuvIfZ8ABB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_video(url, video_output_path = 'videos', video_output_file_name='downloadedVideo'):\n",
        "    try:\n",
        "      yt = YouTube(url)\n",
        "\n",
        "      # Get the highest resolution video stream\n",
        "      video = yt.streams.get_highest_resolution()\n",
        "\n",
        "      if not os.path.exists(video_output_path):\n",
        "        os.makedirs(video_output_path)\n",
        "      \n",
        "      video.download(video_output_path, filename=video_output_file_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: the video is unavaliable\")\n",
        "\n",
        "    # audio_stream = yt.streams.filter(only_audio=True).order_by('abr').desc().first()\n",
        "    # audio_stream.download(output_path=audio_output_path, filename=audio_output_file_name)"
      ],
      "metadata": {
        "id": "TnJmu6ed_TDo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download video\n",
        "# youtube_url = \"https://www.youtube.com/watch?v=agg3C3fzFwY\"\n",
        "youtube_url=\"https://www.youtube.com/watch?v=TQ2K1XTCusc\"\n",
        "download_youtube_video(youtube_url)"
      ],
      "metadata": {
        "id": "ZK9Nt3xZmnYR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def download_audio(url, output_file, desired_format='mp3'):\n",
        "#     yt = YouTube(url)\n",
        "#     stream = yt.streams.filter(only_audio=True).first()\n",
        "#     output_path = stream.download()\n",
        "\n",
        "#     if desired_format not in ['m4a', 'mp3', 'webm', 'mp4', 'mpga', 'wav', 'mpeg']:\n",
        "#         raise ValueError(\"Invalid output format\")\n",
        "\n",
        "#     input_format = stream.subtype\n",
        "#     if input_format != desired_format:\n",
        "#         audio = AudioSegment.from_file(output_path, format=input_format)\n",
        "#         os.remove(output_path)\n",
        "#         output_path = os.path.splitext(output_file)[0] + '.' + desired_format\n",
        "#         audio.export(output_path, format=desired_format)\n",
        "\n",
        "#     os.rename(output_path, output_file)\n",
        "\n",
        "# url = \"https://www.youtube.com/watch?v=TQ2K1XTCusc\"\n",
        "# output_file = \"audio.mp3\"\n",
        "# desired_format = \"mp3\"  # Change this to the desired format\n",
        "# download_audio(url, output_file, desired_format)"
      ],
      "metadata": {
        "id": "ggdCS9tysN7c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJHWd_crRjBx",
        "outputId": "74006cac-369b-4f1d-f329-0c5124675c72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (2.0.0)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (2.0.0+cu118)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (9.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.11.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (16.0.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (67.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->openai-whisper) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796926 sha256=171bf4a066455d791cdaec4bd3e0928aeaf9cfd31064146314d34d5ff2c90880\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/85/e6/0bb9507b8e4f3f6d9c6dcf318bc3514739430375aa8e9eaf5b\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "QlNx4bJ5qyDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d7886e-3cd0-46ec-8dc1-6be2b4e19999"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import whisper\n",
        "import json"
      ],
      "metadata": {
        "id": "UOjzcbJjR8Jg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_video(video_input_path = 'videos', video_input_file_name='downloadedVideo', audio_output_path = 'audios', \n",
        "                     audio_output_file_name='downloadedAudio', audio_format=\"mp3\", transcript_output_path = 'transcipts', \n",
        "                     transcript_output_file_name='whisper_transcript'):\n",
        "  model = whisper.load_model('base')\n",
        "  audio_output_file_name = audio_output_file_name + \".\" + audio_format\n",
        "  video_input = os.path.join(video_input_path, video_input_file_name)\n",
        "  if not os.path.exists(audio_output_path):\n",
        "        os.makedirs(audio_output_path)\n",
        "  if not os.path.exists(transcript_output_path):\n",
        "        os.makedirs(transcript_output_path)\n",
        "  audio_output = os.path.join(audio_output_path, audio_output_file_name)\n",
        "  # ffmpeg = f\"ffpmpeg -i {video_input} -vn -c:a libmp31ame -b:a 192k {audio_output}\"\n",
        "  # subprocess.run(['ffmpeg', '-i', video_input, '-vn','-c:a','libmp31ame','-b:a','192k',audio_output])\n",
        "  cmd = 'ffmpeg -i {} -vn -acodec libmp3lame -q:a 4 {}'.format(video_input, audio_output)\n",
        "  !$cmd\n",
        "  transcript = model.transcribe(audio_output)\n",
        "  trans = ''\n",
        "  for item in transcript['segments']:\n",
        "    trans += (item['text'] + '.')\n",
        "\n",
        "  with open(os.path.join(transcript_output_path, transcript_output_file_name), \"w\") as file:\n",
        "      # Write the content to the file\n",
        "      file.write(trans)\n",
        "  return trans\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "ZHo_b8EKSD7E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = transcribe_video()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvjSs0uvUmxq",
        "outputId": "422b85d1-b43f-43a5-f8e5-09379a43e554"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'videos/downloadedVideo':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2019-12-23T00:46:51.000000Z\n",
            "  Duration: 00:11:07.90, start: 0.000000, bitrate: 371 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 239 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2019-12-23T00:46:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 12/22/2019.\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2019-12-23T00:46:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 12/22/2019.\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audios/downloadedAudio.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    TSSE            : Lavf58.29.100\n",
            "    Stream #0:0(eng): Audio: mp3 (libmp3lame), 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2019-12-23T00:46:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 12/22/2019.\n",
            "      encoder         : Lavc58.54.100 libmp3lame\n",
            "size=    7666kB time=00:11:07.89 bitrate=  94.0kbits/s speed=49.5x    \n",
            "video:0kB audio:7665kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004408%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "s0yXQSthU0Nk",
        "outputId": "aa24a546-809b-4c62-c59e-5b6dcb964be4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" She's a little precious. She's a little precious. Little precious. I. Don't want to call my hair. A. Lovely peaceful day at the castle. Oh look there's a mouse. The. Keep still don't move oh. Oh dear come back here that doesn't sound good. Princess. Princess. Princess. Don't tell. Princess I haven't got it. Another one how many is that five this week. Oh dear princess what's going on I hit another comb why have you done that they hurt my head and today I have a bit of a. Tangle where do you hide them all over. Oh dear maybe I'll take you to the hairdresser no princess is must comb their hair. But I don't like it when she does it she pulls you want me to do it no I want to do it myself. You want to comb your own hair?. All right sweetheart. You can be in charge of combing but if you don't do it the hairdresser will I'll do it. Princess oh really. Oh. Rub it. Where is it?. Help princess there's a terrible sea creature in these waters is that. Look what it's done to this fish. My. Hmm. You're not hiding them anymore I need them I'm in charge of combing mommy sets oh. Yeah. You've been busy calming is hard work I'm getting muscles look impressive. Oh. Oh dear. Hmm have you came to your own hair not yet. I have to do everyone else's first because I'm in charge of combing. Hello. Your turn. I'm in charge of combing my order of the queen. All right. Careful now. Oh dear. Oh thank you very much you're welcome. Have you seen the car. No, I have not. But I want to I think there are misses in my kitchen look. What is the calm for. There they look very pretty. Oh. Princess I can't find pulse and it's his turn. Have you claimed everyone else?. Uh-huh I did the general this morning. I'm the gardener. Oh. And the admiral careful this is my best beer. But I can't find pulse anywhere. Scruff you don't need it you're not messy. Oh. Screw Princess did a time better go. Princess have you seen your hair. Oh. Dinner time oh. Now someone else will do it maybe even the hairdresser. What are you going to do?. Sweet heart I want to look just like you. Oh. Bit cold tonight. Okay, pop it. Oh. Princess missy hair is not come for oh dear I think I need help. That is horrible it's the worst. Rats nest I have ever seen. Rats nest where rats live and worse. Cut it off the rats are coming a board princess. Oh. We can't cut hair no we can't then take me to the hairdresser right now. Please. Come along sweetheart. We'll soon have you sorted bye-bye princess. Nice time. Oh. Marvelous smashing do you. Princess how is the hairdresser she gave me a new comb how lovely just right for combing. Wow. Oh.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbAM8nvNeQhX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "\n",
        "# openai.api_key = \"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\"\n",
        "\n",
        "# def transcribe_audio(file):\n",
        "#     # with open(file_path, \"rb\") as f:\n",
        "#     #     audio_data = f.read()\n",
        "#     audio_file= open(file, \"rb\")\n",
        "#     transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "#     return transcription\n",
        "# transcription = transcribe_audio('audios/downloadedAudio')"
      ],
      "metadata": {
        "id": "84vGNYqyqPRU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slide_video(filepath='videos', filename='downloadedVideo', output_path='images'):\n",
        "  if not os.path.exists(output_path):\n",
        "      os.makedirs(output_path)\n",
        "  cmd = 'ffmpeg -i {}/{} -vf \"fps=1\" {}/%04d.png'.format(filepath, filename, output_path)\n",
        "  !$cmd\n",
        "\n",
        "slide_video('videos','downloadedVideo', 'images')"
      ],
      "metadata": {
        "id": "cRQBMsY-CUFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "iAIkrY3kFvMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "D8kiVbLbEgf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = SentenceTransformer('clip-ViT-B-32-multilingual-v1')"
      ],
      "metadata": {
        "id": "qO_lLxYlGK9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_model = SentenceTransformer('clip-ViT-B-32')"
      ],
      "metadata": {
        "id": "MP9LlPG3KUK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "def load_images_from_directory(directory):\n",
        "    image_tensors = []\n",
        "\n",
        "    for file in sorted(os.listdir(directory)):\n",
        "        # if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "            # Load the image and convert it to RGB mode\n",
        "          # print(file)\n",
        "          image = Image.open(os.path.join(directory, file)).convert('RGB')\n",
        "          \n",
        "          # # Convert the image to a PyTorch tensor and normalize the pixel values\n",
        "          # image_tensor = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
        "\n",
        "          # # Append the image tensor to the list\n",
        "          image_tensors.append(image)\n",
        "\n",
        "    return image_tensors\n",
        "\n",
        "image_directory = 'images'\n",
        "image_tensors = load_images_from_directory(image_directory)\n"
      ],
      "metadata": {
        "id": "VzEjOMa1Ka_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7mTGPfS0vn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_vectors = image_model.encode(image_tensors)"
      ],
      "metadata": {
        "id": "S0jXrgyuOmUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_vectors.shape"
      ],
      "metadata": {
        "id": "D7EGs5ViOvHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_image_directory = 'keyimage'\n",
        "os.makedirs(key_image_directory)"
      ],
      "metadata": {
        "id": "EpYkUmAHQXC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_image_tensor = load_images_from_directory(key_image_directory)\n",
        "key_image_vector = image_model.encode(key_image_tensor)[0]"
      ],
      "metadata": {
        "id": "3uV-4eqnedA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_image_vector.shape"
      ],
      "metadata": {
        "id": "qqIB-1Dz_OBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2qeiMhbq-G3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def find_keyword_index(keyword):\n",
        "#   text_vec = text_model.encode([keyword])\n",
        "#   image_sims = []\n",
        "#   max_sim_index = [float('-inf'), 0]\n",
        "#   for i in range(image_vectors.shape[0]):\n",
        "#     sim = util.cos_sim(text_vec, image_vectors[i])\n",
        "#     if sim > max_sim_index[0]:\n",
        "#       max_sim_index = [sim, i]\n",
        "#     image_sims.append([sim, i])\n",
        "#   return max_sim_index[1]"
      ],
      "metadata": {
        "id": "2N_U23z7SiXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_k_most_matched_indexes(k, output_path='result',source_path ='images',keyword=None, key_image_vector=None):\n",
        "    if keyword is None and key_image_vector is None:\n",
        "        raise ValueError(\"At least one of 'keyword' or 'key_image_vector' must be provided.\")\n",
        "\n",
        "    if keyword is not None:\n",
        "        text_vec = text_model.encode([keyword])\n",
        "\n",
        "    image_sims = []\n",
        "    max_sim_index = [float('-inf'), 0]\n",
        "\n",
        "    for i in range(image_vectors.shape[0]):\n",
        "        sim_keyword = 0\n",
        "        sim_keyimage = 0\n",
        "        count = 0\n",
        "\n",
        "        if keyword is not None:\n",
        "            sim_keyword = util.cos_sim(text_vec, image_vectors[i])\n",
        "            count += 1\n",
        "\n",
        "        if key_image_vector is not None:\n",
        "            sim_keyimage = util.cos_sim(key_image_vector, image_vectors[i])\n",
        "            count += 1\n",
        "\n",
        "        # Calculate the average similarity\n",
        "        sim_avg = (sim_keyword + sim_keyimage) / count\n",
        "\n",
        "        if sim_avg > max_sim_index[0]:\n",
        "            max_sim_index = [sim_avg, i]\n",
        "\n",
        "        image_sims.append([sim_avg, i])\n",
        "    image_sims.sort(reverse=True)\n",
        "    k_most_matched_indexes = image_sims[:k]\n",
        "    for sim, index in k_most_matched_indexes:\n",
        "      if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "      \n",
        "      str_max_sim_index = str(index).zfill(4)\n",
        "      image_path = source_path +  '/' + str_max_sim_index +'.png'\n",
        "      img = Image.open(image_path)\n",
        "      img.save(output_path + '/' + str_max_sim_index + '.png')\n",
        "      img.close()\n",
        "\n",
        "    return k_most_matched_indexes\n"
      ],
      "metadata": {
        "id": "xrs_6NGH-IZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ePhwOUGODQkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "\n",
        "\n",
        "# openai.api_key = \"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\"\n",
        "\n",
        "# def extract_keywords(text):\n",
        "#     prompt = f\"Extract keywords from the following text: '{text}'\"\n",
        "\n",
        "#     response = openai.Completion.create(\n",
        "#         engine=\"text-davinci-002\",\n",
        "#         prompt=prompt,\n",
        "#         max_tokens=50,\n",
        "#         n=1,\n",
        "#         stop=None,\n",
        "#         temperature=0.5,\n",
        "#     )\n",
        "\n",
        "#     keywords = response.choices[0].text.strip()\n",
        "#     return keywords.split(', ')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9-7EG2cCDKbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywordpargraph = 'a man with orange dress and round nose'\n",
        "# keyword = extract_keywords(keywordpargraph)\n",
        "k_most_matched_index = find_k_most_matched_indexes(4, keyword=keywordpargraph, key_image_vector=key_image_vector)\n",
        "# image_tensors[k_most_matched_index[0][1]]\n",
        "for sim, index in k_most_matched_index:\n",
        "  image_tensors[index].show()\n",
        "  print(sim.item())"
      ],
      "metadata": {
        "id": "MPbtoCLmQXLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_tensors[k_most_matched_index[0][1]]"
      ],
      "metadata": {
        "id": "TmB0omsibclY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_most_matched_index = find_k_most_matched_indexes(4, key_image_vector=key_image_vector)\n",
        "# image_tensors[k_most_matched_index[0][1]]\n",
        "for sim, index in k_most_matched_index:\n",
        "  image_tensors[index].show()\n",
        "  print(sim.item())"
      ],
      "metadata": {
        "id": "IV7O7JeBD72d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_sim_index = find_keyword_index(key_image_vector=key_image_vector)\n",
        "# image_tensors[max_sim_index]"
      ],
      "metadata": {
        "id": "tAN48RJpSNHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_peFXlHDfpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}